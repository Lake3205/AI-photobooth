## Analyse

De probleemstelling van onze opdracht is dat generatieve AI-tools zoals ChatGPT, Claude en Midjourney mainstream zijn geworden. Deze tools worden steeds vaker gebruikt in bijvoorbeeld het onderwijs, werk of privé, alleen weinig mensen begrijpen hoe deze tools en de AI-systemen erachter precies werken. Vragen zoals "Wat is een LLM?", "Hoe komt een AI tot een antwoord?" en "Wat zijn de implicaties van het massaal inzetten van deze technologie in het dagelijks leven?" heeft de gemiddelde gebruiker geen antwoord op.

De voornaamste oorzaak is het gebruik aan publieke AI-literacy, ofwel het vermogen om AI-systemen kritisch te begrijpen en gebruiken. Er is behoefte aan nieuwe educatieve en ervaringsgerichte manieren om niet-tech experts bewust te maken van hoe generatieve AI werkt, welke aannames erin zitten, en wat de ethische risico's zijn (denk aan bias, desinformatie, auteursrecht, vervreemding van creatief werk, of afhankelijkheid van black-box systemen).

Voor deze oorzaak hebben wij het afgelopen semester een interventie bedacht aan de hand van de kernvraag: "Hoe kun je via een interactief, provocatief prototype het publiek laten reflecteren op de werking, aannames en gevolgen van generatieve AI-technologieën zoals ChatGPT of Claude?"

Tijdens het project hebben wij verkend hoe wij generatieve AI op een speelse en kritische manier kunnen presenteren aan niet-tech experts. Hierbij hebben we vooral gebruik gemaakt van de bekendste AI-chatbots zoals ChatGPT, Claude en Gemini omdat deze in het dagelijks leven het meest gebruikt worden. We hebben in het begin kort overwogen zelf een AI-model te draaien, maar dit zal voor niet-tech experts mogelijk te complex zijn en wij zagen geen verdere toegevoegde waarde ten opzichte van AI API's. Hieruit viel verder niet echt iets te leren, maar kan wel helpen bij het overbrengen tot niet-tech experts omdat zij waarschijnlijk alleen bekend zijn met deze grote AI-systemen.  
We hebben ook verkend wat voor impact de toevoeging van opgevraagde beredenering van AI-antwoorden en de denkwijze van AI kan hebben op het ondersteunen van het doel van ons project. Hieruit kan je leren dat AI met overtuiging antwoord geeft dat nergens op gebaseerd is, puur zodat de gebruiker antwoord krijgt op zijn/haar vraag. Dit is een van de oorzaken dat AI onbetrouwbaar is en bijvoorbeeld misinformatie verspreidt.  
Tot slot hebben we ook geleerd dat mensen nog weleens geneigd zijn om de antwoorden van AI goed te praten. Op Society 5.0 deden wij alsof we met foto's van mensen aannames lieten genereren door AI (eigenlijk gewoon random hardcoded waarden), en toen mensen zagen dat de AI soms rare of onjuiste aannames deed, probeerden ze dit alsnog te verklaren door bijvoorbeeld lichtinval.